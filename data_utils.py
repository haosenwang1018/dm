import json
import streamlit as st
import re
import hashlib
import streamlit as st

def load_data(filepath):
    """Loads data from the JSON file."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        st.write(f"Loaded {len(data)} articles from {filepath}")
        return data
    except FileNotFoundError:
        st.error(f"Data file not found: {filepath}")
        return []
    except json.JSONDecodeError:
        st.error(f"Error decoding JSON from file: {filepath}")
        return []
    except Exception as e:
        st.error(f"An error occurred loading data: {e}")
        return [] 
    
def filter_documents(raw_data, min_length: int = 200):
    """
    è¿‡æ»¤æ–‡æ¡£åˆ—è¡¨ï¼š
      1. å†…å®¹é•¿åº¦è¿‡æ»¤ï¼šabstract æˆ– content å­—æ®µé•¿åº¦ < min_length æ—¶ä¸¢å¼ƒ
      2. åŽ»é‡ï¼šåŸºäºŽ title+abstract çš„ MD5 å“ˆå¸ŒåŽ»é‡
      3. å™ªå£°æ¸…æ´—ï¼šåŽ»æŽ‰å¸¸è§ HTML æ®‹ç•™æ ‡ç­¾å’Œå¹¿å‘Šæ ‡è®°
    """
    before = len(raw_data)
    seen_hashes = set()
    cleaned = []

    for doc in raw_data:
        text = doc.get("abstract") or doc.get("content") or ""
        # æ¸…ç† HTML æ®‹ç•™
        text = re.sub(r'<[^>]+>', '', text)               # åŽ»æŽ‰æ‰€æœ‰ <...> æ ‡ç­¾
        text = re.sub(r'é˜…è¯»åŽŸæ–‡|å¹¿å‘Š|ç‚¹å‡»äº†è§£æ›´å¤š', '', text)
        doc["abstract"] = text.strip()

        # é•¿åº¦è¿‡æ»¤
        if len(text) < min_length:
            continue

        # åŽ»é‡ï¼šåŸºäºŽ title+text å“ˆå¸Œ
        title = doc.get("title", "").strip()
        h = hashlib.md5((title + text).encode("utf-8")).hexdigest()
        if h in seen_hashes:
            continue
        seen_hashes.add(h)

        cleaned.append(doc)

    after = len(cleaned)
    st.write(f"ðŸ§¹ filter_documents: åŽŸå§‹ {before} æ¡ â†’ è¿‡æ»¤åŽ {after} æ¡")
    return cleaned